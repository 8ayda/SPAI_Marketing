{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3c7d01",
   "metadata": {},
   "source": [
    "# üß† SPAI: Sponsor Visibility Analysis\n",
    "This notebook uses a trained YOLOv8 model to detect sponsor logos in football match frames, calculates their visibility metrics, and uploads the data to a Supabase database.\n",
    "\n",
    "### Key Features:\n",
    "- Detect sponsor logos in frames using YOLOv8\n",
    "- Track logos across frames\n",
    "- Calculate position- and size-based KPI scores\n",
    "- Export results to Supabase\n",
    "\n",
    "> ‚ö†Ô∏è Make sure to configure your `.env` file with Supabase credentials (not shared publicly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q supabase ultralytics opencv-python-headless numpy pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b06663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from supabase import create_client\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount Google Drive to access the trained model\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Supabase credentials from .env file \n",
    "load_dotenv()\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load YOLOv8 model\n",
    "MODEL_PATH = '/content/drive/MyDrive/YOLOv8_models/barca_t_shirt_detection/weights/best.pt'\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZE7G-7ei2Xtw"
   },
   "outputs": [],
   "source": [
    "def calculate_position_score(x_center, y_center, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Calculate position score (1.0 at center, 0.4 at corners)\n",
    "    Higher score for logos in the center of the frame\n",
    "    \"\"\"\n",
    "    # Normalize coordinates to [-1, 1] range\n",
    "    x_norm = 2 * (x_center / frame_width - 0.5)\n",
    "    y_norm = 2 * (y_center / frame_height - 0.5)\n",
    "\n",
    "    # Calculate distance from center (0 at center, 1 at corners)\n",
    "    distance = min(1.0, np.sqrt(x_norm**2 + y_norm**2))\n",
    "\n",
    "    # Convert to score (1.0 at center, 0.4 at corners)\n",
    "    return 1.0 - (0.6 * distance)\n",
    "\n",
    "def determine_position_category(x_center, y_center, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Determine position category based on location in frame\n",
    "    Returns: 'center', 'edge', 'corner', etc.\n",
    "    \"\"\"\n",
    "    # Calculate relative position in frame\n",
    "    x_rel = x_center / frame_width\n",
    "    y_rel = y_center / frame_height\n",
    "\n",
    "    # Define regions\n",
    "    if 0.3 <= x_rel <= 0.7 and 0.3 <= y_rel <= 0.7:\n",
    "        return \"center\"\n",
    "    elif (x_rel < 0.2 and y_rel < 0.2) or (x_rel < 0.2 and y_rel > 0.8) or \\\n",
    "         (x_rel > 0.8 and y_rel < 0.2) or (x_rel > 0.8 and y_rel > 0.8):\n",
    "        return \"corner\"\n",
    "    else:\n",
    "        return \"edge\"\n",
    "\n",
    "def determine_size_category(area_percentage):\n",
    "    \"\"\"\n",
    "    Determine size category based on percentage of frame\n",
    "    Returns: 'small', 'medium', 'large'\n",
    "    \"\"\"\n",
    "    if area_percentage < 1:\n",
    "        return \"small\"\n",
    "    elif area_percentage < 5:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "def process_video(game_id, video_path, sampling_rate=30):\n",
    "    \"\"\"\n",
    "    Process video to detect sponsor logos\n",
    "\n",
    "    Args:\n",
    "        game_id: ID of the game in the database\n",
    "        video_path: Path to the video file\n",
    "        sampling_rate: Process every Nth frame (default: 30, about 1 frame per second for 30fps videos)\n",
    "    \"\"\"\n",
    "    print(f\"Processing game ID: {game_id}\")\n",
    "    print(f\"Video path: {video_path}\")\n",
    "\n",
    "    # Open the video file\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Video properties: {frame_width}x{frame_height}, {fps} fps, {total_frames} frames\")\n",
    "\n",
    "    # Detection results\n",
    "    all_detections = []         # For logo_detections table\n",
    "    logo_appearances = {}       # For tracking and calculating metrics\n",
    "    heatmap_data = {}           # For logo_heatmaps table\n",
    "    timeline_data = []          # For logo_timeline table\n",
    "\n",
    "    # Tracking for continuous sequences\n",
    "    continuous_sequences = {}   # Track continuous appearances for each logo\n",
    "\n",
    "    # Process frames\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process every Nth frame\n",
    "        if frame_count % sampling_rate == 0:\n",
    "            # Calculate timestamp in seconds\n",
    "            timestamp = frame_count / fps\n",
    "\n",
    "            # Run YOLOv8 detection\n",
    "            results = model(frame, conf=0.4)\n",
    "\n",
    "            # Track logos present in this frame\n",
    "            logos_in_frame = set()\n",
    "\n",
    "            # Process each detection\n",
    "            for result in results:\n",
    "                for box, score, cls_id in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
    "                    x1, y1, x2, y2 = box.cpu().numpy().tolist()\n",
    "                    confidence = score.item()\n",
    "                    class_id = int(cls_id.item())\n",
    "                    logo_name = model.names[class_id]\n",
    "\n",
    "                    logos_in_frame.add(logo_name)\n",
    "\n",
    "                    # Calculate center of bounding box\n",
    "                    x_center = (x1 + x2) / 2\n",
    "                    y_center = (y1 + y2) / 2\n",
    "\n",
    "                    # Calculate normalized center for heatmap\n",
    "                    x_center_norm = x_center / frame_width\n",
    "                    y_center_norm = y_center / frame_height\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    position_score = calculate_position_score(x_center, y_center, frame_width, frame_height)\n",
    "                    position_category = determine_position_category(x_center, y_center, frame_width, frame_height)\n",
    "\n",
    "                    bbox_area = (x2 - x1) * (y2 - y1)\n",
    "                    frame_area = frame_width * frame_height\n",
    "                    area_percentage = (bbox_area / frame_area) * 100\n",
    "                    size_category = determine_size_category(area_percentage)\n",
    "\n",
    "                    sponsor_score = position_score * area_percentage\n",
    "\n",
    "                    # Create detection record (logo_detections table)\n",
    "                    detection = {\n",
    "                        \"game_id\": game_id,\n",
    "                        \"timestamp\": round(timestamp, 2),\n",
    "                        \"logo_name\": logo_name,\n",
    "                        \"bbox\": [float(x1), float(y1), float(x2), float(y2)],\n",
    "                        \"confidence\": float(confidence),\n",
    "                        \"position_score\": float(position_score),\n",
    "                        \"area_percentage\": float(area_percentage),\n",
    "                        \"sponsor_score\": float(sponsor_score),\n",
    "                        \"position_category\": position_category,\n",
    "                        \"size_category\": size_category\n",
    "                    }\n",
    "\n",
    "                    all_detections.append(detection)\n",
    "\n",
    "                    # Add to heatmap data (logo_heatmaps table)\n",
    "                    if logo_name not in heatmap_data:\n",
    "                        heatmap_data[logo_name] = []\n",
    "\n",
    "                    heatmap_data[logo_name].append({\n",
    "                        \"x\": float(x_center_norm),\n",
    "                        \"y\": float(y_center_norm),\n",
    "                        \"score\": float(sponsor_score)\n",
    "                    })\n",
    "\n",
    "                    # Track logo appearances for metrics\n",
    "                    if logo_name not in logo_appearances:\n",
    "                        logo_appearances[logo_name] = {\n",
    "                            \"total_time\": 0,\n",
    "                            \"appearances\": 0,\n",
    "                            \"total_area\": 0,\n",
    "                            \"total_position_score\": 0,\n",
    "                            \"frames\": [],\n",
    "                            \"position_counts\": {\"center\": 0, \"edge\": 0, \"corner\": 0},\n",
    "                            \"size_counts\": {\"small\": 0, \"medium\": 0, \"large\": 0},\n",
    "                            \"center_percentage\": 0,\n",
    "                            \"edge_percentage\": 0,\n",
    "                            \"corner_percentage\": 0,\n",
    "                            \"small_percentage\": 0,\n",
    "                            \"medium_percentage\": 0,\n",
    "                            \"large_percentage\": 0\n",
    "                        }\n",
    "\n",
    "                    logo_appearances[logo_name][\"frames\"].append(frame_count)\n",
    "                    logo_appearances[logo_name][\"total_area\"] += area_percentage\n",
    "                    logo_appearances[logo_name][\"total_position_score\"] += position_score\n",
    "                    logo_appearances[logo_name][\"appearances\"] += 1\n",
    "                    logo_appearances[logo_name][\"position_counts\"][position_category] += 1\n",
    "                    logo_appearances[logo_name][\"size_counts\"][size_category] += 1\n",
    "\n",
    "                    # Update continuous sequence tracking for timeline\n",
    "                    if logo_name not in continuous_sequences:\n",
    "                        continuous_sequences[logo_name] = {\n",
    "                            \"start_time\": timestamp,\n",
    "                            \"end_time\": timestamp,\n",
    "                            \"avg_position_score\": position_score,\n",
    "                            \"avg_area\": area_percentage,\n",
    "                            \"avg_sponsor_score\": sponsor_score,\n",
    "                            \"detection_count\": 1\n",
    "                        }\n",
    "                    else:\n",
    "                        # If logo was seen in recent frames, extend sequence\n",
    "                        if timestamp - continuous_sequences[logo_name][\"end_time\"] < (sampling_rate * 2) / fps:\n",
    "                            seq = continuous_sequences[logo_name]\n",
    "                            seq[\"end_time\"] = timestamp\n",
    "                            seq[\"avg_position_score\"] = (seq[\"avg_position_score\"] * seq[\"detection_count\"] + position_score) / (seq[\"detection_count\"] + 1)\n",
    "                            seq[\"avg_area\"] = (seq[\"avg_area\"] * seq[\"detection_count\"] + area_percentage) / (seq[\"detection_count\"] + 1)\n",
    "                            seq[\"avg_sponsor_score\"] = (seq[\"avg_sponsor_score\"] * seq[\"detection_count\"] + sponsor_score) / (seq[\"detection_count\"] + 1)\n",
    "                            seq[\"detection_count\"] += 1\n",
    "                        else:\n",
    "                            # Previous sequence ended, create timeline entry and start new sequence\n",
    "                            seq = continuous_sequences[logo_name]\n",
    "                            timeline_entry = {\n",
    "                                \"game_id\": game_id,\n",
    "                                \"logo_name\": logo_name,\n",
    "                                \"timestamp\": round(seq[\"start_time\"], 2),  # Start time of appearance\n",
    "                                \"sponsor_score\": round(seq[\"avg_sponsor_score\"], 2)\n",
    "                            }\n",
    "                            timeline_data.append(timeline_entry)\n",
    "\n",
    "                            # Start a new sequence\n",
    "                            continuous_sequences[logo_name] = {\n",
    "                                \"start_time\": timestamp,\n",
    "                                \"end_time\": timestamp,\n",
    "                                \"avg_position_score\": position_score,\n",
    "                                \"avg_area\": area_percentage,\n",
    "                                \"avg_sponsor_score\": sponsor_score,\n",
    "                                \"detection_count\": 1\n",
    "                            }\n",
    "\n",
    "            # Check for logos that disappeared in this frame\n",
    "            for logo_name in list(continuous_sequences.keys()):\n",
    "                if logo_name not in logos_in_frame and timestamp - continuous_sequences[logo_name][\"end_time\"] >= (sampling_rate * 2) / fps:\n",
    "                    # Logo is no longer visible for at least 2 sampling intervals, add to timeline\n",
    "                    seq = continuous_sequences[logo_name]\n",
    "                    timeline_entry = {\n",
    "                        \"game_id\": game_id,\n",
    "                        \"logo_name\": logo_name,\n",
    "                        \"timestamp\": round(seq[\"start_time\"], 2),  # Start time of appearance\n",
    "                        \"sponsor_score\": round(seq[\"avg_sponsor_score\"], 2)\n",
    "                    }\n",
    "                    timeline_data.append(timeline_entry)\n",
    "                    del continuous_sequences[logo_name]\n",
    "\n",
    "            if frame_count % 300 == 0:  # Show progress every ~10 seconds\n",
    "                print(f\"Processed frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Add any remaining sequences to timeline\n",
    "    for logo_name, seq in continuous_sequences.items():\n",
    "        timeline_entry = {\n",
    "            \"game_id\": game_id,\n",
    "            \"logo_name\": logo_name,\n",
    "            \"timestamp\": round(seq[\"start_time\"], 2),\n",
    "            \"sponsor_score\": round(seq[\"avg_sponsor_score\"], 2)\n",
    "        }\n",
    "        timeline_data.append(timeline_entry)\n",
    "\n",
    "    # Calculate aggregated metrics\n",
    "    logo_metrics = []\n",
    "    for logo_name, data in logo_appearances.items():\n",
    "        # Calculate total visibility time (approximate)\n",
    "        frames = sorted(data[\"frames\"])\n",
    "        total_frames = 0\n",
    "        current_sequence = []\n",
    "        sequence_durations = []  # To calculate average sequence duration\n",
    "\n",
    "        for frame in frames:\n",
    "            if not current_sequence or frame <= current_sequence[-1] + sampling_rate * 2:  # Allow for gaps\n",
    "                current_sequence.append(frame)\n",
    "            else:\n",
    "                seq_frames = len(current_sequence)\n",
    "                total_frames += seq_frames\n",
    "                sequence_durations.append(seq_frames / fps)\n",
    "                current_sequence = [frame]\n",
    "\n",
    "        if current_sequence:\n",
    "            seq_frames = len(current_sequence)\n",
    "            total_frames += seq_frames\n",
    "            sequence_durations.append(seq_frames / fps)\n",
    "\n",
    "        visibility_time = total_frames / fps\n",
    "        avg_area = data[\"total_area\"] / data[\"appearances\"] if data[\"appearances\"] > 0 else 0\n",
    "        avg_position_score = data[\"total_position_score\"] / data[\"appearances\"] if data[\"appearances\"] > 0 else 0\n",
    "\n",
    "        # Calculate average sequence duration\n",
    "        avg_sequence_duration = sum(sequence_durations) / len(sequence_durations) if sequence_durations else 0\n",
    "\n",
    "        # Calculate position and size percentages\n",
    "        total_positions = sum(data[\"position_counts\"].values())\n",
    "        center_percentage = (data[\"position_counts\"][\"center\"] / total_positions * 100) if total_positions > 0 else 0\n",
    "        edge_percentage = (data[\"position_counts\"][\"edge\"] / total_positions * 100) if total_positions > 0 else 0\n",
    "        corner_percentage = (data[\"position_counts\"][\"corner\"] / total_positions * 100) if total_positions > 0 else 0\n",
    "\n",
    "        total_sizes = sum(data[\"size_counts\"].values())\n",
    "        small_percentage = (data[\"size_counts\"][\"small\"] / total_sizes * 100) if total_sizes > 0 else 0\n",
    "        medium_percentage = (data[\"size_counts\"][\"medium\"] / total_sizes * 100) if total_sizes > 0 else 0\n",
    "        large_percentage = (data[\"size_counts\"][\"large\"] / total_sizes * 100) if total_sizes > 0 else 0\n",
    "\n",
    "        # Determine dominant position and size\n",
    "        dominant_position = max(data[\"position_counts\"], key=data[\"position_counts\"].get)\n",
    "        dominant_size = max(data[\"size_counts\"], key=data[\"size_counts\"].get)\n",
    "\n",
    "        # Calculate sponsorship value (example formula)\n",
    "        size_weight = min(2.0, 0.5 + avg_area / 10)  # Size weight: 0.5-2.0\n",
    "        position_weight = avg_position_score  # Position weight: 0.4-1.0\n",
    "        rate = 100  # Arbitrary base rate per second\n",
    "        value = visibility_time * rate * size_weight * position_weight\n",
    "\n",
    "        # Calculate unique appearances (number of sequences)\n",
    "        unique_appearances = len(sequence_durations)\n",
    "\n",
    "        metrics = {\n",
    "            \"game_id\": game_id,\n",
    "            \"logo_name\": logo_name,\n",
    "            \"visibility_time\": round(visibility_time, 2),\n",
    "            \"appearances\": data[\"appearances\"],\n",
    "            \"unique_appearances\": unique_appearances,\n",
    "            \"avg_sequence_duration\": round(avg_sequence_duration, 2),\n",
    "            \"avg_area_percentage\": round(avg_area, 2),\n",
    "            \"avg_position_score\": round(avg_position_score, 2),\n",
    "            \"dominant_position\": dominant_position,\n",
    "            \"dominant_size\": dominant_size,\n",
    "            \"center_percentage\": round(center_percentage, 2),\n",
    "            \"edge_percentage\": round(edge_percentage, 2),\n",
    "            \"corner_percentage\": round(corner_percentage, 2),\n",
    "            \"small_percentage\": round(small_percentage, 2),\n",
    "            \"medium_percentage\": round(medium_percentage, 2),\n",
    "            \"large_percentage\": round(large_percentage, 2),\n",
    "            \"sponsorship_value\": round(value, 2)\n",
    "        }\n",
    "\n",
    "        logo_metrics.append(metrics)\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    detections_df = pd.DataFrame(all_detections)\n",
    "    metrics_df = pd.DataFrame(logo_metrics)\n",
    "    timeline_df = pd.DataFrame(timeline_data)\n",
    "\n",
    "    # Save results to Supabase\n",
    "    save_to_supabase(game_id, detections_df, metrics_df, timeline_df, heatmap_data)\n",
    "\n",
    "    print(f\"Completed processing game {game_id}\")\n",
    "    print(f\"Detected {len(all_detections)} logo instances\")\n",
    "    print(f\"Found {len(logo_metrics)} unique logos\")\n",
    "    print(f\"Created {len(timeline_data)} timeline entries\")\n",
    "\n",
    "    return detections_df, metrics_df, timeline_df, heatmap_data\n",
    "\n",
    "def save_to_supabase(game_id, detections_df, metrics_df, timeline_df, heatmap_data):\n",
    "    \"\"\"Save all detection data to Supabase\"\"\"\n",
    "    try:\n",
    "        # 1. Save detailed detections\n",
    "        try:\n",
    "            batch_size = 1000  # Insert in batches to avoid payload limits\n",
    "            for i in range(0, len(detections_df), batch_size):\n",
    "                batch = detections_df.iloc[i:i+batch_size].to_dict('records')\n",
    "                supabase.table(\"logo_detections\").insert(batch).execute()\n",
    "                print(f\"Saved batch {i//batch_size + 1} of detections\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving logo_detections: {str(e)}\")\n",
    "            # Create local backup file\n",
    "            detections_df.to_csv(f\"detections_{game_id}.csv\", index=False)\n",
    "            print(f\"Saved detections to detections_{game_id}.csv\")\n",
    "\n",
    "        # 2. Save aggregated metrics\n",
    "        try:\n",
    "            supabase.table(\"logo_metrics\").insert(metrics_df.to_dict('records')).execute()\n",
    "            print(\"Saved logo metrics\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving logo_metrics: {str(e)}\")\n",
    "            metrics_df.to_csv(f\"metrics_{game_id}.csv\", index=False)\n",
    "            print(f\"Saved metrics to metrics_{game_id}.csv\")\n",
    "\n",
    "        # 3. Save timeline data\n",
    "        try:\n",
    "            batch_size = 1000  # Insert in batches to avoid payload limits\n",
    "            for i in range(0, len(timeline_df), batch_size):\n",
    "                batch = timeline_df.iloc[i:i+batch_size].to_dict('records')\n",
    "                supabase.table(\"logo_timeline\").insert(batch).execute()\n",
    "                print(f\"Saved batch {i//batch_size + 1} of timeline entries\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving logo_timeline: {str(e)}\")\n",
    "            timeline_df.to_csv(f\"timeline_{game_id}.csv\", index=False)\n",
    "            print(f\"Saved timeline to timeline_{game_id}.csv\")\n",
    "\n",
    "        # 4. Save heatmap data\n",
    "        try:\n",
    "            for logo_name, positions in heatmap_data.items():\n",
    "                heatmap_entry = {\n",
    "                    \"game_id\": game_id,\n",
    "                    \"logo_name\": logo_name,\n",
    "                    \"positions\": positions\n",
    "                }\n",
    "                supabase.table(\"logo_heatmaps\").insert(heatmap_entry).execute()\n",
    "            print(\"Saved heatmap data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving logo_heatmaps: {str(e)}\")\n",
    "            with open(f\"heatmap_{game_id}.json\", 'w') as f:\n",
    "                json.dump(heatmap_data, f)\n",
    "            print(f\"Saved heatmap data to heatmap_{game_id}.json\")\n",
    "\n",
    "        # 5. Update game status to \"processed\"\n",
    "        try:\n",
    "            supabase.table(\"games\").update({\n",
    "                \"status\": \"processed\",\n",
    "                \"status_message\": \"Processing completed successfully\"\n",
    "            }).eq(\"id\", game_id).execute()\n",
    "            print(f\"Updated game {game_id} status to 'processed'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating game status: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to Supabase: {str(e)}\")\n",
    "        # Save data locally as backup\n",
    "        detections_df.to_csv(f\"detections_{game_id}.csv\", index=False)\n",
    "        metrics_df.to_csv(f\"metrics_{game_id}.csv\", index=False)\n",
    "        timeline_df.to_csv(f\"timeline_{game_id}.csv\", index=False)\n",
    "        with open(f\"heatmap_{game_id}.json\", 'w') as f:\n",
    "            json.dump(heatmap_data, f)\n",
    "        print(f\"Saved backup data to CSV/JSON files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AES6fphawhw"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Fetch pending games\n",
    "    pending_games = fetch_pending_games()\n",
    "    print(f\"Found {len(pending_games)} pending games to process\")\n",
    "\n",
    "    if not pending_games:\n",
    "        print(\"No pending games found\")\n",
    "        return\n",
    "\n",
    "    for game in pending_games:\n",
    "        game_id = game[\"id\"]\n",
    "        video_path = game[\"video_path\"]\n",
    "\n",
    "        try:\n",
    "            process_video(game_id, video_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}: {str(e)}\")\n",
    "            # Update status to \"error\" in case of failure\n",
    "            supabase.table(\"games\").update({\n",
    "                \"status\": \"error\",\n",
    "                \"status_message\": f\"Error: {str(e)[:200]}\"  # Truncate long error messages\n",
    "            }).eq(\"id\", game_id).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cla0UsZDa3hy"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
